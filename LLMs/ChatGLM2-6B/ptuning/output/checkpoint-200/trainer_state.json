{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 6.0263653483992465,
  "eval_steps": 500,
  "global_step": 200,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.3013182674199623,
      "grad_norm": 0.041579462587833405,
      "learning_rate": 0.0099,
      "loss": 4.4638,
      "step": 10
    },
    {
      "epoch": 0.6026365348399246,
      "grad_norm": 0.042861633002758026,
      "learning_rate": 0.0098,
      "loss": 3.3899,
      "step": 20
    },
    {
      "epoch": 0.903954802259887,
      "grad_norm": 0.019731702283024788,
      "learning_rate": 0.0097,
      "loss": 2.9816,
      "step": 30
    },
    {
      "epoch": 1.2052730696798493,
      "grad_norm": 0.00803113542497158,
      "learning_rate": 0.0096,
      "loss": 2.8857,
      "step": 40
    },
    {
      "epoch": 1.5065913370998116,
      "grad_norm": 0.006006977520883083,
      "learning_rate": 0.0095,
      "loss": 2.8,
      "step": 50
    },
    {
      "epoch": 1.807909604519774,
      "grad_norm": 0.006892246659845114,
      "learning_rate": 0.0094,
      "loss": 2.828,
      "step": 60
    },
    {
      "epoch": 2.109227871939736,
      "grad_norm": 0.0068437703885138035,
      "learning_rate": 0.009300000000000001,
      "loss": 2.7785,
      "step": 70
    },
    {
      "epoch": 2.4105461393596985,
      "grad_norm": 0.006782567128539085,
      "learning_rate": 0.0092,
      "loss": 2.7223,
      "step": 80
    },
    {
      "epoch": 2.711864406779661,
      "grad_norm": 0.011153936386108398,
      "learning_rate": 0.0091,
      "loss": 2.7488,
      "step": 90
    },
    {
      "epoch": 3.0131826741996233,
      "grad_norm": 0.016328509896993637,
      "learning_rate": 0.009000000000000001,
      "loss": 2.766,
      "step": 100
    },
    {
      "epoch": 3.3145009416195856,
      "grad_norm": 0.02455553039908409,
      "learning_rate": 0.0089,
      "loss": 2.789,
      "step": 110
    },
    {
      "epoch": 3.615819209039548,
      "grad_norm": 0.015264970250427723,
      "learning_rate": 0.0088,
      "loss": 2.6697,
      "step": 120
    },
    {
      "epoch": 3.9171374764595104,
      "grad_norm": 0.021795786917209625,
      "learning_rate": 0.0087,
      "loss": 2.7002,
      "step": 130
    },
    {
      "epoch": 4.218455743879472,
      "grad_norm": 0.022938553243875504,
      "learning_rate": 0.0086,
      "loss": 2.7149,
      "step": 140
    },
    {
      "epoch": 4.519774011299435,
      "grad_norm": 0.032675404101610184,
      "learning_rate": 0.0085,
      "loss": 2.7192,
      "step": 150
    },
    {
      "epoch": 4.821092278719397,
      "grad_norm": 0.03407915309071541,
      "learning_rate": 0.0084,
      "loss": 2.6928,
      "step": 160
    },
    {
      "epoch": 5.12241054613936,
      "grad_norm": 0.03350664675235748,
      "learning_rate": 0.0083,
      "loss": 2.6526,
      "step": 170
    },
    {
      "epoch": 5.423728813559322,
      "grad_norm": 0.027505118399858475,
      "learning_rate": 0.008199999999999999,
      "loss": 2.7324,
      "step": 180
    },
    {
      "epoch": 5.725047080979285,
      "grad_norm": 0.023669935762882233,
      "learning_rate": 0.008100000000000001,
      "loss": 2.7482,
      "step": 190
    },
    {
      "epoch": 6.0263653483992465,
      "grad_norm": 0.030947253108024597,
      "learning_rate": 0.008,
      "loss": 2.6727,
      "step": 200
    }
  ],
  "logging_steps": 10,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 31,
  "save_steps": 100,
  "total_flos": 1.1765871996095693e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
